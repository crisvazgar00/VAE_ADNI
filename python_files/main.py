from load_database import find_pet, load_img_nii, split_database, transform_string, extract_id_ses_from_path, merge_id_ses_to_ADNIMERGE
from load_database import merge_lists, split_list
from normalisation import normalization_min, normalization_cerebellum
from debugging import make_grid_recon, tensor_to_nii, reconstruction_diff
from plot_results import plot_latent_space_ADAS, SVR_ADAS, plot_latentx_vs_ADAS
from plot_results import plot_latent_space_VENTRICLES, plot_latentx_vs_VENTRICLES, SVR_VENTRICLES
from VAE_model import VAE, VAE_encoder, VAE_decoder
import os
import sys
import numpy as np
import yaml
import nibabel as nib
import matplotlib.pyplot as plt
import torch
from torch.utils.tensorboard import SummaryWriter
import pandas as pd
from torchvision.io import decode_image
from pathlib import Path
import random
from torchvision.utils import make_grid
from sklearn.svm import LinearSVR
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from colorama import Fore, Style, init





def model_VAE(config):
    latent = config['model']['latent']
    model = VAE(encoder=VAE_encoder(latent),
                    decoder=VAE_decoder(latent))
    return model




def generate_batches(data, config):
    """
    Function to generate batches for training. Yield
    means that this function is a generator and returns a batch
    of data every time it's called. Since yield is inside of
    for loop every time it's called it will advance one step inside
    the loop.
    
    """
    batch_size = config['model']['batch_size']
    device = config['experiment']['device']
    n_batches = len(data) // batch_size
    #len(data) // batch_size is not a whole number. That's why bellow we introduce 
    #min((batch_idx + 1) * batch_size, len(data))
    
    for batch_idx in range(n_batches+1):
        # 0*4 = 0, 1*4 = 4, 4*2 = 8, ... (if batch_size = 4)
        start_idx = batch_idx * batch_size
        # 1*4 = 4, 2*4 = 8, ... (it is always batch_size steps ahead of start_idx)
        # We use min in the case end_idx is lower than len(data) in order not to exclude any data element
        end_idx = min((batch_idx + 1) * batch_size, len(data))
        batch_data = torch.from_numpy(np.array(data[start_idx:end_idx], dtype=np.float32)) \
                 .requires_grad_(True) \
                 .to(device)
        yield batch_data


#_________________________________________________

#               TRAINING
#_________________________________________________



def epoch_train(model, train_set, optimizer, config):
    """
    This function performs training during an epoch in batches.
    Iterates over batches generated by "generate_batches", compute
    model to obtain latent space and reconstructed image and finally
    compute loss. Loss of entire epoch is computed as average of batches
    losses.
        Args:
            -model: deep network model.
            -train_set: list of volumes for training.
            -optimizer: optimizer for training.
            -device: device to perform computation.
            -config: config file to load hyperparameters.
        
        Output:
            - Loss of an epoch.
    
    """ 
    
    model.train()
    
    beta = config['model']['loss']['beta']
    batch_size = config['model']['batch_size']
    div_criteria = config['model']['divergence']
    loss_epoch = 0.0
    loss_epoch_div = 0.0
    loss_epoch_recon = 0.0
    batch_count = 0
    
    
    
    for batch in generate_batches(train_set, config):
        
        #print(batch_count)
        #print(f'len of batch: {len(batch)}')
        
        optimizer.zero_grad()
        #Obtain reconstructed images and latent space of the batch
        x_recon_batch, z, z_mean, z_logvar = model(batch)
        
        if len(x_recon_batch.shape) == 5: # ndim
            x_recon_batch = x_recon_batch.squeeze(1)
        #Compute the loss of the batch
        loss_batch, loss_train_div, loss_train_recon = model.loss(device, div_criteria, batch, x_recon_batch, z_mean, z_logvar, beta, batch_size)
        
        #print(f'Loss batch: {loss_batch.item()}, Loss_batch_div: {loss_train_div.item()}, Loss_batch_recon: {loss_train_recon.item()}')
        
        loss_batch.backward()
        optimizer.step()
        
        
        loss_epoch += loss_batch.item()
        loss_epoch_div += loss_train_div.item()
        loss_epoch_recon += loss_train_recon.item()
        batch_count += 1
        
    #Average over total number of batches
    loss_epoch /= batch_count
    loss_epoch_div /= batch_count
    loss_epoch_recon /= batch_count
    
    return loss_epoch, loss_epoch_div, loss_epoch_recon






def train(config, model, train_set, eval_set, epochs):
    
    writer = SummaryWriter() #Keep track of data through tensorboard
    
    device_name = config['experiment']['device']
    device = torch.device(device_name if torch.cuda.is_available() else 'cpu')
    best_loss_eval = float('inf')
    latent_dim = config['model']['latent']
    results_folder = 'results'
    
    #Load model into cuda device and choose optimizer
    model = model.to(device)
    if config['model']['optimizer'] == 'adam':
        optimizer = torch.optim.Adam(model.parameters(), lr = config['model']['lr'])
    else: raise ValueError("Invalid optimizer")

    for epoch in range(epochs):
        #Train the model for this epoch
        print(f'{Fore.YELLOW} Epoch nÂº: {epoch}')
        loss_epoch, loss_epoch_div, loss_epoch_recon = epoch_train(model, train_set, optimizer, config)
        
        #Perform validation of the model
        loss_eval_epoch, loss_eval_div, loss_eval_recon = evaluation(model, eval_set, device, config, epoch)
        
        #Keep track through tensorboard
        writer.add_scalar('Loss/train', loss_epoch, epoch)
        writer.add_scalars('Loss_train/div-recon', {'loss train div' : loss_epoch_div, 'loss train recon' : loss_epoch_recon} , epoch)
        
        writer.add_scalar('Loss/evaluation', loss_eval_epoch, epoch)
        writer.add_scalars('Loss_evaluation/div_recon', {'loss eval div' : loss_eval_div, 'loss eval recon': loss_eval_recon}, epoch)
        
        writer.add_scalars('Loss/train-evaluation', {'loss train' : loss_epoch, 'loss evaluation' : loss_eval_epoch} , epoch)


        print(f'Epoch loss training: {loss_epoch}, validation loss: {loss_eval_epoch}')
        print(f'Epoch div loss: {loss_epoch_div}, Epoch recon loss: {loss_epoch_recon}')
        
        # improvement_threshold = 0.01  
        # if (best_loss_eval - loss_eval_epoch) / best_loss_eval > improvement_threshold:
          if (best_loss_eval < loss_eval_epoch)
            best_loss_eval = loss_eval_epoch
            with open(os.path.join(results_folder, 'best_loss_eval.txt'), 'w') as file:
                file.write(f'{best_loss_eval}\n')
        model_save_path = 'vae_model.pth'
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss_train': loss:epoch,
            'loss_eval': loss_eval_epoch,
            'loss_eval_div': loss_eval_div,
            'loss_eval_recon': loss_eval_recon,
            'latent_dim': latent_dim
        }, model_save_path)
        print(f'Modelo guardado en {model_save_path}')


    return model

#______________________________________

#           EVALUATION
#______________________________________


def evaluation(model, eval_set, device, config, epoch):
    model.eval()
    
    beta = config['model']['loss']['beta']
    div_criteria = config['model']['divergence']
    batch_size = config['model']['batch_size']
    count = 0
    
    loss_eval = 0.0
    loss_eval_div = 0.0
    loss_eval_recon = 0.0
    
    random_idx = random.sample(range(int(len(eval_set) / batch_size)), 1)
    
    
    with torch.no_grad():
        for x in generate_batches(eval_set, config):
            x_tensor = x.clone().detach().float().to(device)
            
            recon_eval, _, z_mean, z_logvar = model(x_tensor)
            
            if count == random_idx:
                string_idx = f'epoch{epoch}_eval{count}'
                make_grid_recon(recon_eval, string_idx)
            
            
            if len(recon_eval.shape) == 5:
                recon_eval = recon_eval.squeeze(1)
            
            loss_eval_batch , loss_eval_div_batch, loss_eval_recon_batch = model.loss(device, div_criteria, x_tensor, recon_eval, z_mean, z_logvar, beta, batch_size)
            
            loss_eval += loss_eval_batch.item()
            loss_eval_div += loss_eval_div_batch.item()
            loss_eval_recon += loss_eval_recon_batch
            count += 1
        
        loss_eval /= count
        loss_eval_div /= count
        loss_eval_recon /= count
        
        return loss_eval, loss_eval_div, loss_eval_recon


#_________________________________

#           TESTING
#__________________________________



def test(config, test_set, model):
    """
    This function performs testing on the test dataset.
    Set model to .eval() and torch.no_grad() to ensure model
    does not change. Encode and decode test images using trained model.
    Compute loss between real images and reconstructed data to check validity
    of the model.
    """
    model.eval()
    
    results_folder = 'results'
    
    batch_size = config['model']['batch_size']
    #random_batch_index = random.randint(0, batch_size - 1)  # Elegir un batch aleatorio
    #print(f'Random batch idx: {random_batch_index}')
     
    #Load hyperparameters and device
    beta = config['model']['loss']['beta']
    div_criteria = config['model']['divergence']
    device_name = config['experiment']['device']
    device = torch.device(device_name if torch.cuda.is_available() else 'cpu')
        
    #Load model again into cuda device
    model = model.to(device)
    loss_test = 0.0
    count = 0
    recon_img_list = []
    z_list = []
    z_mean_list = []
    z_logvar_list = []
        
    input_tensor = np.array(test_set)
    # Convert numpy array to a PyTorch tensor
    input_tensor = torch.tensor(input_tensor, dtype=torch.float32).to(device)

        
    with torch.no_grad():
        for x in generate_batches(test_set, config):
            
            recon_batch, z, z_mean, z_logvar = model(x)
            
            if count % 20 == 0:
                #print(f'shape of recon_batch_ {recon_batch.shape}')
                string_1 = f'test_recon_batchnum_{count}'
                make_grid_recon(recon_batch, string_1)
                string_2 = f'test_input_batchnum_{count}'
                x = x.unsqueeze(1)
                make_grid_recon(x, string_2)
            
            if len(recon_batch.shape) == 5:
                recon_batch = recon_batch.squeeze(1)
            recon_img_list.extend(recon_batch)
            z_list.extend(z)
            z_mean_list.extend(z_mean)
            z_logvar_list.extend(z_logvar)

            
            loss_batch, _, _ = model.loss(device, div_criteria, x, recon_batch, z_mean, z_logvar, beta, batch_size)
            loss_test += loss_batch
            count += 1
        
        loss_test /= count
        
        print(f'Total loss of testing: {loss_test}') 
        
        
        with open(os.path.join(results_folder, 'z_test.txt'), 'w') as file:
            for item in z_list:
                item = item.detach().cpu().numpy()
                file.write(f'{item}\n')
                
        with open(os.path.join(results_folder, 'z_mean_test.txt'), 'w') as file:
            for item in z_mean_list:
                item = torch.exp(0.5 * z_logvar)
                item = item.detach().cpu().numpy()
                file.write(f'{item}\n')                
                
        with open(os.path.join(results_folder, 'z_logvar_test.txt'), 'w') as file:
            for item in z_logvar_list:
                item = torch.exp(0.5 * z_logvar)
                item = item.detach().cpu().numpy()
                file.write(f'{item}\n')
            
    return recon_img_list, z_list




#___________________________________________________________________________________




if __name__ == '__main__':
    
    if sys.stdout.isatty():
       init(autoreset=True)
    else:
        init(autoreset=True, strip=True) 
        
    config_file = 'config.yaml'
    
    #CREATE FOLDER FOR RESULTS
    results_folder = "results"
    
    model_save_path = 'vae_model.pth'
    if not os.path.exists(results_folder):
        os.makedirs(results_folder)
        
    
    #LOAD HYPERPARAMETERS FROM CONFIG FILE

    with open(config_file, 'r') as file:
        config = yaml.safe_load(file)

    folder = config['loader']['load_folder']['folder']
    prefix = config['loader']['load_folder']['prefix']
    extension = config['loader']['load_folder']['extension']
    target_folder_name = config['loader']['load_folder']['target_folder_name']
    div_criteria = config['model']['divergence']
    print(f'Using divergence {div_criteria}')
    
    epochs = config['model']['epochs']    
    device_name = config['experiment']['device']
    device = torch.device(device_name if torch.cuda.is_available() else 'cpu')
    
    print(f"Using device: {device}")
    splits = config['loader']['splits']
    path_ADNIMERGE = config['loader']['load_ADNIMERGE']
    normalization = config['experiment']['normalization']
    
    
    #LOAD IMAGES AND APPLY NORMALIZATION
    imgs_paths = find_pet(folder, prefix, extension, target_folder_name)
    imgs_list = load_img_nii(imgs_paths)
    
    print(f'Loading of images terminated.')
    
    #OBTAIN ID AND SESSION AND TRANSFORM INTO ADNIMERGE FORMAT
    id_ses_list = extract_id_ses_from_path(imgs_paths)
    id_ses_list_formated = transform_string(id_ses_list)
    
    #CHOOSE BETWEEN RAW DATA OR NORMALISED DATA
    if normalization == True:
        imgs_list_norm = normalization_min(imgs_list)
        print(f'Normalization of images terminated')
        #MERGE IMGS_LIST_NORM INTO (ID, SES) LIST 
        imgs_IDSES_tuple = merge_lists(imgs_list_norm, id_ses_list_formated)
    else:
        imgs_IDSES_tuple = merge_lists(imgs_list, id_ses_list_formated)
            

    
    #MERGE INTO A LIST OF FORMAT (PATH, (IMGS, (ID, SES)))
    #TO KEEP TRACK OF IDs
    paths_imgs_IDSES_tuple = merge_lists(imgs_paths, imgs_IDSES_tuple)
    
    #SPLIT DATABASE
    train_set, eval_set, test_set = split_database(paths_imgs_IDSES_tuple, splits)
    
    
    _, train_set = split_list(train_set) #SPLIT INTO (PATH) AND (IMG, (ID, SES))
    train_set, _ = split_list(train_set) #SPLIT INTO (IMG) ((ID,SES))

    _, eval_set = split_list(eval_set)
    eval_set, _ = split_list(eval_set)

    #WE ONLY NEED (ID, SES) FOR TEST SET AND PATHS FOR DEBUGGING
    path_test, test_set = split_list(test_set)
    test_set, test_id_ses = split_list(test_set)
    
    
    paths_test_dir = os.path.join(results_folder, "paths_test_dir")
    if not os.path.exists(os.path.join(paths_test_dir)):
        os.makedirs(paths_test_dir)
        
    with open(f'{paths_test_dir}/paths_test.txt', 'w') as file:
        for item in path_test:
            file.write(f'{item}\n')    
    
    

    print(f'Length of train_set: {len(train_set)}, eval_set: {len(eval_set)}')
    print(f'Length of test_set: {len(test_set)}. Length of (ID, SES) list: {len(test_id_ses)}')
    
    df_ADNIMERGE = pd.read_csv(path_ADNIMERGE)
    
    #LOAD MODEL AND TRAIN
    model = model_VAE(config)
    print('____________________________________________')
    print(Fore.RED + 'Start of training')
    model = train(config, model, train_set, eval_set, epochs)  
    print(Fore.RED + 'Training terminated')
    print('____________________________________________')
    
    print('Loading best saved model')
    checkpoint = torch.load(model_save_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    #PERFORM TESTING
    recon_eval_imgs_list, z_test_list = test(config, test_set, model)
    print(Fore.CYAN + 'Test terminated')
    
    print('Starting plot of results')
    plot_latent_space_ADAS(z_test_list, test_id_ses, df_ADNIMERGE, path_test, config)
    plot_latentx_vs_ADAS(z_test_list, test_id_ses, df_ADNIMERGE, path_test, config)
    plot_latent_space_VENTRICLES(z_test_list, test_id_ses, df_ADNIMERGE, path_test, config)
    plot_latentx_vs_VENTRICLES(z_test_list, test_id_ses, df_ADNIMERGE, path_test, config)
    SVR_ADAS(z_test_list, test_id_ses, df_ADNIMERGE, path_test, config)
    SVR_VENTRICLES(z_test_list, test_id_ses, df_ADNIMERGE, path_test, config)
    