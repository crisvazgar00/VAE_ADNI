from load_database import find_pet, load_img_nii, normalization_cerebellum, split_database, transform_string, extract_id_ses_from_path, merge_id_ses_to_ADNIMERGE
from VAE_model import VAE, VAE_encoder, VAE_decoder
import os
import sys
import numpy as np
import yaml
import nibabel as nib
import matplotlib.pyplot as plt
import torch
from torch.utils.tensorboard import SummaryWriter
import pandas as pd



def model_VAE(config):
    latent = config['model']['latent']
    model = VAE(encoder=VAE_encoder(latent),
                    decoder=VAE_decoder(latent))
    return model




def generate_batches(data, config):
    """
    Function to generate batches for training. Yield
    means that this function is a generator and returns a batch
    of data every time it's called. Since yield is inside of
    for loop every time it's called it will advance one step inside
    the loop.
    
    """
    batch_size = config['model']['batch_size']
    device = config['experiment']['device']
    n_batches = len(data) // batch_size
    #len(data) // batch_size is not a whole number. That's why bellow we introduce 
    #min((batch_idx + 1) * batch_size, len(data))
    
    for batch_idx in range(n_batches):
        # 0*4 = 0, 1*4 = 4, 4*2 = 8, ... (if batch_size = 4)
        start_idx = batch_idx * batch_size
        # 1*4 = 4, 2*4 = 8, ... (it is always batch_size steps ahead of start_idx)
        # We use min in the case end_idx is lower than len(data) in order not to exclude any data element
        end_idx = min((batch_idx + 1) * batch_size, len(data))
        batch_data = torch.tensor(np.array(data[start_idx:end_idx], dtype=np.float32)).to(device)
        yield batch_data





def epoch_train(model, train_set, optimizer, config):
    """
    This function performs training during an epoch in batches.
    Iterates over batches generated by "generate_batches", compute
    model to obtain latent space and reconstructed image and finally
    compute loss. Loss of entire epoch is computed as average of batches
    losses.
        Args:
            -model: deep network model.
            -train_set: list of volumes for training.
            -optimizer: optimizer for training.
            -device: device to perform computation.
            -config: config file to load hyperparameters.
        
        Output:
            - Loss of an epoch.
    
    """ 
    
    model.train()
    
    beta = config['model']['loss']['beta']
    batch_size = config['model']['batch_size']
    div_criteria = config['model']['divergence']
    loss_epoch = 0.0
    batch_count = 0
    
    for batch in generate_batches(train_set, config):
        
        optimizer.zero_grad()
        #Obtain reconstructed images and latent space of the batch
        x_recon_batch, z, z_mean, z_logvar = model(batch)
        
        if len(x_recon_batch.shape) == 5:
            x_recon_batch = x_recon_batch.squeeze(1)
        #Compute the loss of the batch
        _, _, loss_batch = model.loss(device, div_criteria, batch, x_recon_batch, z_mean, z_logvar, beta, batch_size)
        
        loss_batch.backward()
        optimizer.step()
        loss_epoch += loss_batch.item()
        batch_count += 1
        
    #Average over total number of batches
    loss_epoch /= batch_count
    
    return loss_epoch






def train(config, model, train_set, eval_set, epochs):
    
    writer = SummaryWriter() #Keep track of data through tensorboard
    
    device_name = config['experiment']['device']
    device = torch.device(device_name if torch.cuda.is_available() else 'cpu')
    
    print(f"Using device: {device}")
    
    
    #Load model into cuda device and choose optimizer
    model = model.to(device)
    if config['model']['optimizer'] == 'adam':
        optimizer = torch.optim.Adam(model.parameters(), lr = config['model']['lr'])
    else: raise ValueError("Invalid optimizer")

    loss_train = 0.0
    for epoch in range(epochs):
        #Train the model for this epoch
        print(f'epoch nÂº: {epoch}')
        loss_epoch = epoch_train(model, train_set, optimizer, config)
        loss_train += loss_epoch
        
        #Perform validation of the model
        loss_eval = evaluation(model, eval_set, device, config)
        
        #Keep track through tensorboard
        writer.add_scalar('Loss/train', loss_epoch, epoch)
        writer.add_scalar('Loss/evaluation', loss_eval, epoch)
        writer.add_scalars('Loss/train-evaluation', {'loss train' : loss_epoch, 'loss evaluation' : loss_eval} , epoch)

        
        print(f'Epoch loss: {loss_epoch}, validation loss: {loss_eval}')
    writer.close()
        
    loss_train /= epochs

    return model


def evaluation(model, eval_set, device, config):
    model.eval()
    
    beta = config['model']['loss']['beta']
    div_criteria = config['model']['divergence']
    
    eval_loss = 0.0
    
    with torch.no_grad():
        for x in eval_set:
            x_tensor = torch.tensor(x, dtype=torch.float32).to(device)
            
            recon_eval, _, z_mean, z_logvar = model(x_tensor)
            
            if len(x_tensor.shape) == 3:
                #Add dimension for [Batch_size] to fit expected dimensions in DSSIM
                x_tensor = x_tensor.unsqueeze(0)
                
            if len(recon_eval.shape) == 5:
                #Remove extra dimension [Channel] from shape
                recon_eval = recon_eval.squeeze(1)
            
            _, _, loss_eval = model.loss(device, div_criteria, x_tensor, recon_eval, z_mean, z_logvar, beta, batch_size = 1)
            
            eval_loss += loss_eval
        
        eval_loss /= len(eval_set)
        
        return eval_loss





def test(config, test_set, model):
    """
    This function performs testing on the test dataset.
    Set model to .eval() and torch.no_grad() to ensure model
    does not change. Encode and decode test images using trained model.
    Compute loss between real images and reconstructed data to check validity
    of the model.
    """
    model.eval()
    recon_test_imgs_list = []
    with torch.no_grad():
        
        #Load hyperparameters and device
        beta = config['model']['loss']['beta']
        div_criteria = config['model']['divergence']
        device_name = config['experiment']['device']
        device = torch.device(device_name if torch.cuda.is_available() else 'cpu')
    
        print(f"Using device: {device}")
        
        #Load model again into cuda device
        model = model.to(device)
        
        loss_img = 0.0
        count = 0
        loss_test = 0.0
        
        for img in test_set:
            #send img to GPU
            input_tensor = torch.tensor(img, dtype=torch.float32).to(device)
            
            #We need to add an extra dimension for [Batch_size] because it is
            #needed for x.shape[0] in DSSIM computation
            if len(input_tensor.shape) == 3:
                input_tensor = input_tensor.unsqueeze(0)
            #Encode and decode img
            recon_img, z, z_mean, z_logvar = model(input_tensor)    
            
            if len(recon_img.shape) == 5:
                #Remove extra dimension [Channel] from shape
                recon_img = recon_img.squeeze(1)    
            
            #compute loss between reconstructed image and input image
            _, _, loss_img = model.loss(device, div_criteria, input_tensor, recon_img, z_mean, z_logvar, beta, batch_size = 1)
            #print(f'Loss of testing number {count}: {loss_img}')
            
            #Add to list
            recon_test_imgs_list.append(recon_img)
            
            loss_test += loss_img
            count += 1
            
            if count == len(test_set):  #Convert last volume into .nii to check model
                tensor_to_nii(input_tensor, recon_img)
            
        loss_test /= count   
        print(f'Total loss of testing: {loss_test}') 
            
    return recon_test_imgs_list



def tensor_to_nii(x_input, x_recon):
    """
    This function transforms an input volume tensor 'x_input' into a .nii
    volume 'x_recon'
    """
    
    x_recon = x_recon.squeeze(0) #Erase channel dimension
    x_numpy = x_recon.cpu().detach().numpy()
    x_nifti_recon = nib.Nifti1Image(x_numpy, affine = np.eye(4))
    
    x_input = x_input.squeeze(0)
    x_input = x_input.cpu().detach().numpy()
    x_nifti_input = nib.Nifti1Image(x_input, affine = np.eye(4))
    nib.save(x_nifti_recon, 'reconstructed_test_volume.nii')
    nib.save(x_nifti_input, 'normalised_test_volume.nii')
    return 






def sample_latent_space(z_list):
    """
    Function for plotting latent_dim x against latent_dim for test_set.
    Each point in the scatterplot is colorcoded by its ADAS score.
    """
    
    dim_0 = [lat[0] for lat in z_list]
    dim_1 = [lat[1] for lat in z_list]
    
    plt.scatter(dim_0, dim_1)
    plt.xlabel('Latent dim 0')
    plt.ylabel('Latent dim 1')
    plt.title ('Latent dim 0 vs latent dim 1')
    plt.grid(True)
    plt.show()












if __name__ == '__main__':
    config_file = 'config.yaml'
    
    #LOAD HYPERPARAMETERS FROM CONFIG FILE

    with open(config_file, 'r') as file:
        config = yaml.safe_load(file)

    folder = config['loader']['load_folder']['folder']
    prefix = config['loader']['load_folder']['prefix']
    extension = config['loader']['load_folder']['extension']
    target_folder_name = config['loader']['load_folder']['target_folder_name']
    
    epochs = config['model']['epochs']    
    device = config['experiment']['device']
    
    
    #LOAD IMAGES AND APPLY NORMALIZATION
    imgs_paths = find_pet(folder, prefix, extension, target_folder_name)
    imgs_list = load_img_nii(imgs_paths)
    imgs_list_norm = normalization_cerebellum(config, imgs_list)

    #SPLIT DATASET INTO TRAINING, VALIDATION AND TEST
    splits = config['loader']['splits']
    train_set, eval_set, test_set = split_database(imgs_list_norm, splits)
    print(f'Length of train_set: {len(train_set)}, eval_set: {len(eval_set)}, test_set: {len(test_set)}')
    
    #LOAD ADNIMERGE DATASET AND FILTER WITH AVAILABLE SUBJECTS
    path_ADNIMERGE = config['loader']['load_ADNIMERGE']   
    ADNIMERGE_df = pd.read_csv(path_ADNIMERGE)
    available_tuple_id_ses = extract_id_ses_from_path(imgs_paths)
    transformed_available_tuple_id_ses = transform_string(available_tuple_id_ses)
    #MERGE TRANSFORMED TUPLE LIST OF AVAILABLE SUBJECTS AND ADNIMERGE
    df_ADNI_BIDS_ID_SES_ADAS = merge_id_ses_to_ADNIMERGE(transformed_available_tuple_id_ses, ADNIMERGE_df)
    
    #LOAD MODEL AND TRAIN
    model = model_VAE(config)
    model = train(config, model, train_set, eval_set, epochs)  
    print(f'Training terminated')
    
    #PERFORM TESTING
    recon_eval_imgs_list = test(config, test_set, model)
    

    