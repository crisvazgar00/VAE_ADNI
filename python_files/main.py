from load_database import find_pet, load_img_nii, normalization_cerebellum, split_database
from VAE_model import VAE, VAE_encoder, VAE_decoder
import os
import sys
import numpy as np
import yaml
import nibabel as nib
import matplotlib.pyplot as plt
import torch
from torch.utils.tensorboard import SummaryWriter



def model_VAE(config):
    latent = config['model']['latent']
    model = VAE(encoder=VAE_encoder(latent),
                    decoder=VAE_decoder(latent))
    return model




def generate_batches(data, config):
    """
    Function to generate batches for training. Yield
    means that this function is a generator and returns a batch
    of data every time it's called. Since yield is inside of
    for loop every time it's called it will advance one step inside
    the loop.
    
    """
    batch_size = config['model']['batch_size']
    device = config['experiment']['device']
    n_batches = len(data) // batch_size
    
    for batch_idx in range(n_batches):
        # 0*4 = 0, 1*4 = 4, 4*2 = 8, ... (if batch_size = 4)
        start_idx = batch_idx * batch_size
        # 1*4 = 4, 2*4 = 8, ... (it is always batch_size steps ahead of start_idx)
        # We use min in the case end_idx is lower than len(data) in order not to exclude any data element
        end_idx = min((batch_idx + 1) * batch_size, len(data))
        batch_data = torch.tensor(np.array(data[start_idx:end_idx], dtype=np.float32)).to(device)
        yield batch_data





def epoch_train(model, train_set, optimizer, config):
    """
    This function performs training during an epoch in batches.
    Iterates over batches generated by "generate_batches", compute
    model to obtain latent space and reconstructed image and finally
    compute loss. Loss of entire epoch is computed as average of batches
    losses.
        Args:
            -model: deep network model.
            -train_set: list of volumes for training.
            -optimizer: optimizer for training.
            -device: device to perform computation.
            -config: config file to load hyperparameters.
        
        Output:
            - Loss of an epoch.
    
    """ 
    
    model.train()
    
    beta = config['model']['loss']['beta']
    batch_size = config['model']['batch_size']
    loss_epoch = 0.0
    batch_count = 0
    
    for batch in generate_batches(train_set, config):
        
        optimizer.zero_grad()
        #Obtain reconstructed images and latent space of the batch
        #print(f'Hola, estoy justo entre optimizer.zero_grad y model(batch)')
        x_recon_batch, z, z_mean, z_logvar = model(batch)
        #print(f'Hola, estoy justo DESPUES de model(batch)')
        if len(x_recon_batch.shape) == 5:
            x_recon_batch = x_recon_batch.squeeze(1)
        #Compute the loss of the batch
        _, _, loss_batch = model.loss(batch, x_recon_batch, z_mean, z_logvar, beta, batch_size)
        
        loss_batch.backward()
        optimizer.step()
        loss_epoch += loss_batch.item()
        batch_count += 1
        
    #Average over total number of batches
    loss_epoch /= batch_count
    
    return loss_epoch






def train(config, model, train_set, eval_set, epochs):
    
    writer = SummaryWriter() #Keep track of data through tensorboard
    
    device_name = config['experiment']['device']
    device = torch.device(device_name if torch.cuda.is_available() else 'cpu')
    
    print(f"Using device: {device}")
    
    
    #Load model into cuda device and choose optimizer
    model = model.to(device)
    if config['model']['optimizer'] == 'adam':
        optimizer = torch.optim.Adam(model.parameters(), lr = config['model']['lr'])
    else: raise ValueError("Invalid optimizer")

    loss_train = 0.0
    for epoch in range(epochs):
        #Train the model for this epoch
        print(f'epoch nÂº: {epoch}')
        loss_epoch = epoch_train(model, train_set, optimizer, config)
        loss_train += loss_epoch
        
        #Perform validation of the model
        loss_eval = evaluation(model, eval_set, device, config)
        
        #Keep track through tensorboard
        writer.add_scalar('Loss/train', loss_epoch, epoch)
        writer.add_scalar('Loss/evaluation', loss_eval, epoch)
        writer.add_scalar('Loss/train-evaluation', loss_epoch, epoch)
        writer.add_scalar('Loss/train-evaluation', loss_eval, epoch)
        
        print(f'Epoch loss: {loss_epoch}, validation loss: {loss_eval}')
    writer.close()
        
    loss_train /= epochs

    return model


def evaluation(model, eval_set, device, config):
    model.eval()
    
    beta = config['model']['loss']['beta']
    
    eval_loss = 0.0
    
    with torch.no_grad():
        for x in eval_set:
            x_tensor = torch.tensor(x, dtype=torch.float32).to(device)
            
            recon_eval, _, z_mean, z_logvar = model(x_tensor)
            
            if len(x_tensor.shape) == 3:
                #Add dimension for [Batch_size] to fit expected dimensions in DSSIM
                x_tensor = x_tensor.unsqueeze(0)
                
            if len(recon_eval.shape) == 5:
                #Remove extra dimension [Channel] from shape
                recon_eval = recon_eval.squeeze(1)
            
            _, _, loss_eval = model.loss(x_tensor, recon_eval, z_mean, z_logvar, beta, batch_size = 1)
            
            eval_loss += loss_eval
        
        eval_loss /= len(eval_set)
        
        return eval_loss




def test(config, test_set, model):
    """
    This function performs testing on the test dataset.
    Set model to .eval() and torch.no_grad() to ensure model
    does not change. Encode and decode test images using trained model.
    Compute loss between real images and reconstructed data to check validity
    of the model.
    """
    model.eval()
    recon_test_imgs_list = []
    with torch.no_grad():
        
        #Load hyperparameters and device
        beta = config['model']['loss']['beta']
        device_name = config['experiment']['device']
        device = torch.device(device_name if torch.cuda.is_available() else 'cpu')
    
        print(f"Using device: {device}")
        
        #Load model again into cuda device
        model = model.to(device)
        
        loss_img = 0.0
        count = 0
        loss_test = 0.0
        
        for img in test_set:
            #send img to GPU
            input_tensor = torch.tensor(img, dtype=torch.float32).to(device)
            
            #We need to add an extra dimension for [Batch_size] because it is
            #needed for x.shape[0] in DSSIM computation
            if len(input_tensor.shape) == 3:
                input_tensor = input_tensor.unsqueeze(0)
            #Encode and decode img
            recon_img, z, z_mean, z_logvar = model(input_tensor)    
            
            if len(recon_img.shape) == 5:
                #Remove extra dimension [Channel] from shape
                recon_img = recon_img.squeeze(1)    
            
            #compute loss between reconstructed image and input image
            _, _, loss_img = model.loss(input_tensor, recon_img, z_mean, z_logvar, beta, batch_size = 1)
            #print(f'Loss of testing number {count}: {loss_img}')
            
            #Add to list
            recon_test_imgs_list.append(recon_img)
            
            loss_test += loss_img
            count += 1
            
        loss_test /= count   
        print(f'Total loss of testing: {loss_test}') 
            
    return recon_test_imgs_list




if __name__ == '__main__':
    config_file = 'config.yaml'

    with open(config_file, 'r') as file:
        config = yaml.safe_load(file)

    folder = config['loader']['load_folder']['folder']
    prefix = config['loader']['load_folder']['prefix']
    extension = config['loader']['load_folder']['extension']
    target_folder_name = config['loader']['load_folder']['target_folder_name']
    
    epochs = config['model']['epochs']    

    #Load images and normalise them
    imgs_paths = find_pet(folder, prefix, extension, target_folder_name)
    imgs_list = load_img_nii(imgs_paths)
    imgs_list_norm = normalization_cerebellum(imgs_list)

    #Split dataset intro three sets
    splits = config['loader']['splits']
    train_set, eval_set, test_set = split_database(imgs_list_norm, splits)
    print(f'Length of train_set: {len(train_set)}, eval_set: {len(eval_set)}, test_set: {len(test_set)}')
    
    #Load model and perform training
    model = model_VAE(config)
    model = train(config, model, train_set, eval_set, epochs)  
    print(f'Training terminated')
    
    #Perform testing
    recon_eval_imgs_list = test(config, test_set, model)
    

    